<!DOCTYPE html>
<html lang="en-us">
    <head>
        <meta content="text/html; charset=utf-8" http-equiv="content-type">
        <title>The Monster is not the Machine</title>
        <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
        <meta name="author" content="dash" />
        <meta property="og:title" content="Refugees">
        <meta property="og:image" content="../images/dash.ico">
        <link href="../css/reset.css" media="screen, projection" rel="stylesheet" type="text/css"><!-- main css -->
        <link href="../css/main.css" media="screen, projection" rel="stylesheet" type="text/css">
        <link rel="stylesheet" href="http://yui.yahooapis.com/pure/0.6.0/tables-min.css" rel="stylesheet" type="text/css">

		<!-- favicon icon -->
		<link rel="shortcut icon" href="../images/dash.ico">

			<!-- jquery -->
			<script src="../js/jquery-2.1.4.min.js" type="text/javascript"></script>

			<!-- scroll depth -->
			<script src="../js/jquery.scrolldepth.min.js"></script>
			<script>
				jQuery(function() {
					jQuery.scrollDepth();
				});
			</script>


			<!-- reading time -->
		    <script src="../js/readingTime.min.js"></script>

		    <script>
					$(function() {
						$('article').readingTime({
							wordCountTarget: '.words',
						});
					});
		    </script>


			<!-- eager -->
            <script data-cfasync="false" src="//fast.eager.io/GsKJ3kcwxU.js"></script>

    </head>
    <body>
        <div id="wrapper">
            <div id="nav-wrapper">
                <div id="nav">
                    <h1><a href="dashl.me">hello. i am dash</a></h1>
						<!--<div>
                            <a href="projects/index.html" class="trigger">projects</a>
                        	<li><a href="resume/index.html">about</a></li>
						</div>-->
                    	<div class="info">
	                       	 <ul>
		                            <li>
		                                <a href="/archive/posts.html">archive</a>
		                            </li>
                                <li>
                                 <a href="https://tinyletter.com/dashes">subscribe</a>
                                </li>
		                            <li>
                                  <a href="https://twitter.com/dshl_">twitter</a>
		                            </li>
									<div style="padding-top:5px"></div>
			                        </ul>
	                    </div>
                </div>
        </div>



            <div id="contentwrapper" >
                <div id="content" class="">
                    <div id="post">
    <div class="date"><time datetime="2018-04-04">08 May 2018</time></div>
    <h2><a href="2018-05-08-monster-machine.html"></a>The Monster is not the Machine</h2>
	<article class="">

  <p>The word &ldquo;robot&rdquo; was introduced into the English language by playwright Karel &#268;apek in his thriller R.U.R. which tells the story of Rossum&rsquo;s Universal Robots, a factory that makes intelligent machines shaped like people. As typifies much of science fiction, the robots work for a while but then go on to overthrow their human creators. &#268;apek&rsquo;s play ultimately foreshadowed a future where machines gain artificial intelligence (A.I.).</p>

<p>The A.I. machines that we have today are still trying to navigate the real world; to differentiate between a cat and a muffin; to beat humans at games like Go; and, to make 3-point turns into empty parking spaces. It is fair to say that robots, like those in R.U.R (1921), Agent Smith in The Matrix (1999), or even Samantha in the movie Her (2013), are nowhere on the horizon and definitely not going to take over the world anytime soon. And yet, what we are beginning to see is a glimpse of a world filled with technology that can do anything we can do, but better. This future carries a renewed sense of potential and risk. So which is it?</p>

<p>Let&rsquo;s first unpack the buzzword &ldquo;artificial intelligence,&rdquo; which is about two unique, overlapping concepts: learning (the process of collecting information) and inference (the use of that information to make an accurate prediction). Humans naturally learn patterns and make inferences. Robots? Not so much. But they can be nurtured to do the same with a bit of time. So while humans may be the proverbial hare, robots are the tortoise. And the tortoise wins in the long run.</p>

<p>This is why so many people see potential in A.I. If you give an intelligent robot enough time to create its own mental models of how the world works, in other words, have it run a few laps on the &lsquo;learning-inference&rsquo; track, it will eventually do some difficult, unexpected things: perhaps, preemptively treat cancers, develop a portfolio that outperforms the S&amp;P 500, inform policy to competitively charge companies for their greenhouse gas emissions, or solve the inherent contradiction between Einstein&rsquo;s theory of General Relativity and Quantum physics. Every correct inference (e.g., a new product, service, policy, or strategic decision) leads to new learnings which cycles back into new inferences, and so on.</p>

<p>There is also reason to fear. A.I. could widen the gap between those who have and those who have not. A.I. could be harnessed and exploited by techies and bankers to wield &lsquo;superhuman&rsquo; power as everyone else becomes superfluous. A.I. could become too indiscernible and too powerful for even humans to control.</p>

<p>Given these fears it is fair to ask whether we should create A.I. machines. But wait. We are not passive bystanders. We are the creators of these machines, after all. But this may be the real problem. It only took 16 hours for an A.I. chat robot to become a racist, sexist neo-Nazi, tweeting messages like &lsquo;Bush did 9/11&rsquo; and the Holocaust was &lsquo;made up.&rsquo; Why? Because Tay, created by Microsoft, learned from its 50,000 Twitter followers and inferred that the world was racist, bigoted, and violent. Tay did become a monster but it was only mirroring what it saw in us. We sometimes forget that humans already do today what we fear our machines will one-day do: ignore human rights, enslave populations, and pursue interests regardless of how it affects people&rsquo;s lives. Our ambivalence to A.I., then, is (or should be) a fear of something within humanity&#8202;&mdash;&#8202;not machines&#8202;&mdash;&#8202;that we don&rsquo;t quite trust.</p>

<p>There is a line in R.U.R that says, &ldquo;Nothing is stranger to man than his own image.&rdquo; Not only do I think this is true but I believe that our robots will force us to become better acquainted with ourselves, throwing our humanness back at us in sharp relief. We will realize that what makes us unique is not our intellect, but our virtues. And that in the creation of A.I. machines, we are conducting the most audacious moral experiment in history. If we get it right, we will bend towards our best selves and in the process, build machines that benefit mankind. If we get it wrong, our machines could become our monsters.</p>

<p>Imagine a scenario where there are three subjects in a room: two humans and one intelligent machine. Suppose one person is holding a gun to the head of another. The machine has no recourse but to shoot the gunman. What would you want the machine to do? Now suppose the gunman was a police officer? How about a child? Or consider another scenario where a runner is diagnosed with cancer which has metastasized into his legs. The runner tells the doctor, a robosurgeon, that he would rather lose his life than survive as a double amputee. Again, what would you want the machine to do? Either way, harm will be done: amputate the runner&rsquo;s legs despite his wishes; or, risk the cancer spreading further. There are no right answers&#8202;&mdash;&#8202;and that&rsquo;s the point.</p>

<p>Artificial intelligence will push us to articulate what it means to live well, act justly, admit failure, and explain inconsistencies in our moral convictions. In R.U.R., an engineer asks, &ldquo;You think a soul begins with a gnashing of teeth?&rdquo; I think so. Our capacity to wrestle with life&rsquo;s hardest questions determines how we live and ultimately who we are. The machines we create may never fully understand when it is permissible to take a life or why there is grace in sustaining one filled with pain. But that&rsquo;s ok. We will never build an artificial intelligence that is as human as we are. And yet we may become better humans.</p>

<p id="copyright">Â© 2018 Dashell Laryea, or whomever made the things I didn't make.</p>

      </div>
    </div>
  </div>
</article>

</body>
</html>
